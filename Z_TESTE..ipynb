{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2345SA#124']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "retorno = re.findall(\"^[0-9]{2}([^@]+)\",\"952345SA#124@APNNE\")\n",
    "retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import ftplib\n",
    "import patoolib\n",
    "import botocore\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import logging\n",
    "import traceback\n",
    "from zipfile import ZipFile\n",
    "from dateutil import rrule\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "assume_role_cache: dict = {}\n",
    "def assumed_role_session(role_arn: str, base_session: botocore.session.Session = None):\n",
    "    base_session = base_session or boto3.session.Session()._session\n",
    "    fetcher = botocore.credentials.AssumeRoleCredentialFetcher(\n",
    "        client_creator = base_session.create_client,\n",
    "        source_credentials = base_session.get_credentials(),\n",
    "        role_arn = role_arn,\n",
    "        extra_args = {\n",
    "        #    'RoleSessionName': None # set this if you want something non-default\n",
    "        }\n",
    "    )\n",
    "    creds = botocore.credentials.DeferredRefreshableCredentials(\n",
    "        method = 'assume-role',\n",
    "        refresh_using = fetcher.fetch_credentials,\n",
    "        time_fetcher = lambda: datetime.datetime.now(tzlocal())\n",
    "    )\n",
    "    botocore_session = botocore.session.Session()\n",
    "    botocore_session._credentials = creds\n",
    "    return boto3.Session(botocore_session = botocore_session)\n",
    "\n",
    "\n",
    "# usage:\n",
    "session = assumed_role_session('arn:aws:iam::274674695952:role/service-role/LambdaRole')\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Variaveis\n",
    "S3_BUCKET_NAME = 'abrasel-datalake'\n",
    "\n",
    "PATH_FOLDER = '/tmp/'\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = s3_resource.Bucket(S3_BUCKET_NAME)\n",
    "\n",
    "url_base = 'http://200.152.38.155/CNPJ/'\n",
    "OUTPUT_DIR = 's3://abrasel-datalake/raw/CNPJ/cnpj_estabele/'\n",
    "\n",
    "def extract_file(url, file_name):\n",
    "    # faz requisição ao servidor\n",
    "\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        if response.status_code == requests.codes.OK:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=32768):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Download finalizado em {file_name}\")\n",
    "        else:\n",
    "            response.raise_for_status()       \n",
    "\n",
    "    \"\"\"\n",
    "    resposta = requests.get(url)\n",
    "    if resposta.status_code == requests.codes.OK:\n",
    "        with open(file_name, 'wb') as cnpj_estabelecimento:\n",
    "            cnpj_estabelecimento.write(resposta.content)\n",
    "        print(f\"Download finalizado em {file_name}\")\n",
    "    else:\n",
    "        resposta.raise_for_status()\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    #Lista os objetos dentro do bucket\n",
    "    response = s3.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=\"raw/CNPJ/cnpj_estabele/\")\n",
    "    try:\n",
    "        files_in_folder = response[\"Contents\"]\n",
    "        for file in files_in_folder:\n",
    "            name_to_delete = [{'Key': file['Key']}]\n",
    "            # Deleta os objetos dentro do bucket\n",
    "            s3.delete_objects(Bucket=S3_BUCKET_NAME, Delete={'Objects': name_to_delete})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        BASE_URL = f'{url_base}Estabelecimentos{i}.zip'\n",
    "        name_file = f'Estabelecimentos{i}.zip'\n",
    "        full_path = os.path.join(PATH_FOLDER,name_file)\n",
    "        extract_file(url=BASE_URL,file_name=full_path)\n",
    "        logging.info(full_path)\n",
    "        logging.info(\"Download finalizado in /tmp/..\")\n",
    "        with ZipFile(full_path, \"r\") as zip_code:\n",
    "            zip_code.extractall(PATH_FOLDER)\n",
    "        print(zip_code.namelist())\n",
    "        \n",
    "        print(\"Dados descompactados..\")\n",
    "        \n",
    "        name_unzip = zip_code.namelist()\n",
    "        for name in name_unzip:\n",
    "            print(name)\n",
    "            path_unzip = f'{PATH_FOLDER}{name}'\n",
    "            #bucket.upload_file(path_unzip, f\"raw/CNPJ/cnpj_estabele/{name}\")\n",
    "            s3.upload_file(f\"{path_unzip}\", S3_BUCKET_NAME, f\"raw/CNPJ/cnpj_estabele/{name}\")\n",
    "        print(\"Download Finalizado..\")\n",
    "        \n",
    "            \n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Hello from Lambda!')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import os\n",
    "import logging\n",
    "from zipfile import ZipFile\n",
    "import botocore\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "# Variáveis\n",
    "S3_BUCKET_NAME = 'abrasel-datalake'\n",
    "PATH_FOLDER = '/tmp/'\n",
    "url_base = 'http://200.152.38.155/CNPJ/'\n",
    "OUTPUT_DIR = 's3://abrasel-datalake/raw/CNPJ/cnpj_estabele/'\n",
    "\n",
    "# Criação da sessão com função IAM assumida\n",
    "def assumed_role_session(role_arn: str, base_session: botocore.session.Session = None):\n",
    "    base_session = base_session or boto3.session.Session()._session\n",
    "    fetcher = botocore.credentials.AssumeRoleCredentialFetcher(\n",
    "        client_creator = base_session.create_client,\n",
    "        source_credentials = base_session.get_credentials(),\n",
    "        role_arn = role_arn,\n",
    "        extra_args = {\n",
    "            # 'RoleSessionName': None # Defina isso se desejar algo não padrão\n",
    "        }\n",
    "    )\n",
    "    creds = botocore.credentials.DeferredRefreshableCredentials(\n",
    "        method = 'assume-role',\n",
    "        refresh_using = fetcher.fetch_credentials,\n",
    "        time_fetcher = lambda: datetime.now(tzlocal())\n",
    "    )\n",
    "    botocore_session = botocore.session.Session()\n",
    "    botocore_session._credentials = creds\n",
    "    return boto3.Session(botocore_session = botocore_session)\n",
    "\n",
    "# usage:\n",
    "session = assumed_role_session('arn:aws:iam::274674695952:role/service-role/LambdaRole')\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Criação de recurso usando a sessão assumida\n",
    "s3_resource = session.resource('s3')\n",
    "bucket = s3_resource.Bucket(S3_BUCKET_NAME)\n",
    "\n",
    "def extract_and_upload_file(url, file_name):\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=32768):\n",
    "                    f.write(chunk)\n",
    "            logging.info(f\"Download finalizado em {file_name}\")\n",
    "\n",
    "            with ZipFile(file_name, \"r\") as zip_code:\n",
    "                zip_code.extractall(PATH_FOLDER)\n",
    "                extracted_files = zip_code.namelist()\n",
    "\n",
    "                for extracted_file in extracted_files:\n",
    "                    local_path = os.path.join(PATH_FOLDER, extracted_file)\n",
    "                    s3_key = os.path.join(OUTPUT_DIR, extracted_file)\n",
    "                    s3.upload_file(local_path, S3_BUCKET_NAME, s3_key)\n",
    "\n",
    "        os.remove(file_name)\n",
    "        logging.info(f\"Download, extraction, and upload completed for {file_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during processing: {str(e)}\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        # Deleta os objetos dentro do bucket\n",
    "        objects_to_delete = [{'Key': obj.key} for obj in bucket.objects.filter(Prefix=OUTPUT_DIR)]\n",
    "        if objects_to_delete:\n",
    "            logging.info(objects_to_delete)\n",
    "            s3.delete_objects(Bucket=S3_BUCKET_NAME, Delete={'Objects': objects_to_delete})\n",
    "        \n",
    "        for i in range(5):\n",
    "            file_url = f'{url_base}Estabelecimentos{i}.zip'\n",
    "            file_name = os.path.join(PATH_FOLDER, f'Estabelecimentos{i}.zip')\n",
    "            extract_and_upload_file(file_url, file_name)\n",
    "        \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps('Process completed successfully!')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps('An error occurred during processing.')\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculo_daora(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    elif y == 1:\n",
    "        return x\n",
    "    else : \n",
    "        return x +calculo_daora(x,y-1)\n",
    "\n",
    "valor = calculo_daora(2,500)\n",
    "valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requisicao(uf:str=\"MG\"):\n",
    "    import requests\n",
    "    # Request da api na sensedia\n",
    "    url = \"https://api.abrasel.com.br/dev.api/v1/estabelecimentos\"\n",
    "    client_id = {\"client_id\": \"b78911f9-68ad-4b71-aca8-8dc21237b506\"}\n",
    "    params = {\n",
    "        \"cidade\":\"ARCOS\",\n",
    "        \"uf\":uf,\n",
    "        \"associados\":\"ATIVO\",\n",
    "        \"bandeira\" :\"ticket\",\n",
    "        \"pageSize\":\"50\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url=url, headers=client_id, params=params)\n",
    "\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Error forwarding call to back-end server. Message: Connect to ec2-52-67-164-51.sa-east-1.compute.amazonaws.com:3000 [ec2-52-67-164-51.sa-east-1.compute.amazonaws.com/52.67.164.51] failed: Connection refused (Connection refused)\n",
      "[]\n",
      "Error forwarding call to back-end server. Message: Connect to ec2-52-67-164-51.sa-east-1.compute.amazonaws.com:3000 [ec2-52-67-164-51.sa-east-1.compute.amazonaws.com/52.67.164.51] failed: Connection refused (Connection refused)\n",
      "[]\n",
      "Error forwarding call to back-end server. Message: Connect to ec2-52-67-164-51.sa-east-1.compute.amazonaws.com:3000 [ec2-52-67-164-51.sa-east-1.compute.amazonaws.com/52.67.164.51] failed: Connection refused (Connection refused)\n"
     ]
    }
   ],
   "source": [
    "UFS = [\"SP\", \"MG\", \"PE\", \"RO\", \"AC\", \"RJ\"]\n",
    "import time \n",
    "for uf in UFS:\n",
    "    time.sleep(1)\n",
    "    requisicao(uf=uf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
