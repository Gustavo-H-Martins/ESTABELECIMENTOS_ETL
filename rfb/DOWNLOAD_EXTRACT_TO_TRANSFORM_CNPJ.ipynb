{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libs necessárias\n",
    "def request(url:str = None,nome_arquivo:str = '', extensao:str='zip'):\n",
    "    \"\"\"AI is creating summary for request\n",
    "\n",
    "    Args:\n",
    "        url (str): Caminho online de onde possam ter redirecionamentos href.\n",
    "        nome_arquivo (str): nome do arquivo que vamos buscar ou dos arquivos se tiverem mais de um com o mesmo nome.\n",
    "        extensao (str): extenção do arquivo que vamos buscar se formos buscar por um download em específico.\n",
    "\n",
    "    Returns:\n",
    "        urls : Retorna uma lista com todos as urls que deram math com os parâmetros passados no crawler da url infomrada.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import urllib.request\n",
    "    nome_arquivo = nome_arquivo.capitalize()\n",
    "    print(nome_arquivo)\n",
    "    abre_url = urllib.request.urlopen(url)\n",
    "    \n",
    "    le_url = abre_url.read()\n",
    "\n",
    "    converte_leitura_url = le_url.decode(\"utf8\")\n",
    "    abre_url.close()\n",
    "    \n",
    "    urls = []\n",
    "    #urls = [ f\"{url}{i.replace('<', '')}\" for i in re.findall(f\"[\\w\\d]+.(?:zip|pdf|csv)<\", converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    #urls = [f'{url}{i}.zip' for i in re.findall(f'href=\"(.*?).{extensao}', converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    urls = [ f\"{url}{i}.{extensao}\" for i in re.findall(f'href=\"(.*).(?:{extensao})\"', converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    \n",
    "    return urls\n",
    "def download(url:str=None, salvar_onde:str= './' ):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        url (str): URL de do arquivo para download.\n",
    "        salvar_onde (str): Pasta de destino do arquivo baixado.\n",
    "    \"\"\"\n",
    "    from pySmartDL import SmartDL\n",
    "    obj = SmartDL(url, salvar_onde)\n",
    "    obj.start()\n",
    "    path = obj.get_dest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links = [\"https://dadosabertos.rfb.gov.br/CNPJ/\", \"http://200.152.38.155/CNPJ/\"]\n",
    "src = request(links[1])\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "class EXTRATOR_CNPJ: \n",
    "    def __init__(self, url:str = None,nome_arquivo:str = '', extensao:str='zip'): \n",
    "        self.url = url \n",
    "        self.nome_arquivo = nome_arquivo\n",
    "        self.extensao = extensao \n",
    "        self.CNPJ_ESQUEMA =  {\n",
    "                        \"EMPRESAS\" : {\n",
    "                                \"_c0\" : \"CNPJ_BASE\",\n",
    "                                \"_c1\" : \"RAZAO_SOCIAL\",\n",
    "                                \"_c2\" : \"CODIGO_NATUREZA_JURIDICA\",\n",
    "                                \"_c3\" : \"CODIGO_QUALIFICACAO\",\n",
    "                                \"_c4\" : \"CAPITAL_SOCIAL\",\n",
    "                                \"_c5\" : \"PORTE_EMPRESA\",\n",
    "                                \"_c6\" : \"ENTE_FEDERATIVO\"\n",
    "                                },\n",
    "                        \"ESTABELECIMENTOS\" : {\n",
    "                                \"_c0\" : \"CNPJ_BASE\",\n",
    "                                \"_c1\" : \"CNPJ_ORDEM\",\n",
    "                                \"_c2\" : \"CNPJ_DV\",\n",
    "                                \"_c3\" : \"MATRIZ_FILIAL\",\n",
    "                                \"_c4\" : \"NOME_FANTASIA\",\n",
    "                                \"_c5\" : \"SITUACAO_CADASTRAL\",\n",
    "                                \"_c6\" : \"DATA_SITUACAO_CADASTRAL\",\n",
    "                                \"_c7\" : \"CODIGO_MOTIVO_SITUACAO_CADASTRAL\",\n",
    "                                \"_c8\" : \"CIDADE_EXTERIOR\",\n",
    "                                \"_c9\" : \"CODIGO_PAIS\",\n",
    "                                \"_c10\" : \"DATA_INICIO_ATIVIDADE\",\n",
    "                                \"_c11\" : \"CNAE_PRINCIPAL\",\n",
    "                                \"_c12\" : \"CNAE_SECUNDARIO\",\n",
    "                                \"_c13\" : \"TIPO_LOGRADOURO\",\n",
    "                                \"_c14\" : \"LOGRADOURO\",\n",
    "                                \"_c15\" : \"NUMERO\",\n",
    "                                \"_c16\" : \"COMPLEMENTO\",\n",
    "                                \"_c17\" : \"BAIRRO\",\n",
    "                                \"_c18\" : \"CEP\",\n",
    "                                \"_c19\" : \"UF\",\n",
    "                                \"_c20\" : \"CODIGO_MUNICIPIO\",\n",
    "                                \"_c21\" : \"DDD_CONTATO\",\n",
    "                                \"_c22\" : \"TELEFONE_CONTATO\",\n",
    "                                \"_c23\" : \"DDD_COMERCIAL\",\n",
    "                                \"_c24\" : \"TELEFONE_COMERCIAL\",\n",
    "                                \"_c25\" : \"DDD_FAX\",\n",
    "                                \"_c26\" : \"FAX\",\n",
    "                                \"_c27\" : \"EMAIL\",\n",
    "                                \"_c28\" : \"SITUACAO_ESPECIAL\",\n",
    "                                \"_c29\" : \"DATA_SITUACAO_ESPECIAL\"\n",
    "                                },\n",
    "                        \"SIMPLES\" : {\n",
    "                                \"_c0\" : \"CNPJ_BASE\",\n",
    "                                \"_c1\" : \"OPCAO_SIMPLES\",\n",
    "                                \"_c2\" : \"DATA_OPCAO_SIMPLES\",\n",
    "                                \"_c3\" : \"DATA_EXCLUSAO_SIMPLES\",\n",
    "                                \"_c4\" : \"OPCAO_MEI\",\n",
    "                                \"_c5\" : \"DATA_OPCAO_MEI\",\n",
    "                                \"_c6\" : \"DATA_EXCLUSAO_MEI\"\n",
    "                                },\n",
    "                        \"SOCIOS\" :{\n",
    "                                \"_c0\" : \"CNPJ_BASE\",\n",
    "                                \"_c1\" : \"TIPO_SOCIO\",\n",
    "                                \"_c2\" : \"NOME_SOCIO\",\n",
    "                                \"_c3\" : \"CPF_CNPJ\",\n",
    "                                \"_c4\" : \"CODIGO_QUALIFICACAO_SOCIO\",\n",
    "                                \"_c5\" : \"DATA_ENTRADA_SOCIEDADE\",\n",
    "                                \"_c6\" : \"PERCENTUAL_CAPITAL_SOCIAL\",\n",
    "                                \"_c7\" : \"CPF_REPRESENTANTE\",\n",
    "                                \"_c8\" : \"NOME_REPRESENTANTE\",\n",
    "                                \"_c9\" : \"CODIGO_QUALIFICACAO_REPRESENTANTE\",\n",
    "                                \"_c10\" : \"FAIXA_ETARIA\"\n",
    "                                },\n",
    "                        \"PAISES\" : {\n",
    "                                \"_c0\" : \"CODIGO_PAIS\", \n",
    "                                \"_c1\" :\"NOME_PAIS\"\n",
    "                                },\n",
    "                        \"MUNICIPIOS\" : {\n",
    "                                \"_c0\" : \"CODIGO_MUNICIPIO\", \n",
    "                                \"_c1\" : \"NOME_MUNICIPIO\"\n",
    "                                },\n",
    "                        \"QUALIFICACOES\" : {\n",
    "                                \"_c0\" :\"CODIGO_QUALIFICACAO\", \n",
    "                                \"_c1\" : \"DESCRIÇAO_QUALIFICACAO\"\n",
    "                                },\n",
    "                        \"NATUREZAS\" : {\n",
    "                                \"_c0\" :\"CODIGO_NATUREZA_JURIDICA\", \n",
    "                                \"_c1\" : \"DESCRICAO_NATUREZA_JURIDICA\"\n",
    "                                },\n",
    "                        \"MOTIVOS\" : {\n",
    "                                \"_c0\" : \"CODIGO_MOTIVO_SITUACAO_CADASTRAL\", \n",
    "                                \"_c1\" :\"DESCRICAO_MOTIVO_SITUACAO_CADASTRAL\"\n",
    "                                },\n",
    "                        \"CNAES\" : {\n",
    "                                \"_c0\" : \"CODIGO_CNAE\",\n",
    "                                \"_c1\" : \"DESCRICAO_CNAE\"\n",
    "                                } \n",
    "                        }\n",
    "    def request(self):\n",
    "        import re\n",
    "        import urllib.request\n",
    "        abre_url = urllib.request.urlopen(self.url)\n",
    "        le_url = abre_url.read()\n",
    "        converte_leitura_url = le_url.decode(\"utf8\")\n",
    "        abre_url.close()\n",
    "        urls = []\n",
    "        urls =  [ f\"{self.url}{i.upper()}.{self.extensao}\" for i in re.findall(f'href=\"(.*).(?:{self.extensao})\"', converte_leitura_url) if i.startswith(self.nome_arquivo)]\n",
    "        return urls\n",
    "\n",
    "    def download(self, url:str=None, destino:str = None):\n",
    "        ### Com requests\n",
    "        \"\"\"\n",
    "        import requests\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "        \"\"\"\n",
    "        ### Com urllib\n",
    "        \"\"\"\n",
    "        import urllib.request\n",
    "        arquivo = url.split('/')[-1]\n",
    "        # faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "        urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "        ### Com SmartDL\n",
    "        \"\"\"\n",
    "\n",
    "        ### Com SmartDL\n",
    "        from pySmartDL import SmartDL\n",
    "\n",
    "        obj = SmartDL(url, destino, threads=4, progress_bar=False)\n",
    "        obj.start()\n",
    "        return destino\n",
    "\n",
    "    def run(self):\n",
    "        import re\n",
    "        import zipfile\n",
    "        from pyspark.sql import SparkSession\n",
    "        from pyspark.sql.functions import input_file_name, lit\n",
    "        urls  = self.request()\n",
    "        \n",
    "        # Define ou busca uma sessão do Spark\n",
    "        spark = SparkSession.builder\\\n",
    "                .master(\"local[2]\")\\\n",
    "                .appName(\"OnlineReader\")\\\n",
    "                .getOrCreate()\n",
    "        for url in urls:\n",
    "            #numero_arquivo = urls.index(url)\n",
    "            # Diretório de execução do script\n",
    "            current_dir = os.getcwd()\n",
    "            \n",
    "            # Pega o nome do arquivo pela url\n",
    "            nome_arquivo_download = url.split('/')[-1]\n",
    "\n",
    "            # Define o caminho absoluto do diretório.\n",
    "            salvar_onde = f\"{current_dir}/RAW/{''.join(filter(str.isalpha,nome_arquivo_download.split('.')[0]))}/\"\n",
    "            \n",
    "            # cria a pasta para armazenar o arquivo, se ela não existir\n",
    "            if not os.path.exists(salvar_onde):\n",
    "                os.makedirs(salvar_onde)\n",
    "                \n",
    "            # download do arquivo zip\n",
    "            path = self.download(url, os.path.join(salvar_onde, nome_arquivo_download))\n",
    "            \n",
    "            # descompactação do arquivo zip\n",
    "            with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "\n",
    "                # obtem o nome do primeiro arquivo dentro do zip\n",
    "                nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "                # define um novo nome para o arquivo\n",
    "                novo_nome_arquivo = f\"CNPJ_{nome_arquivo_download.split('.')[0]}.csv\"\n",
    "                # cria um dicionário com as informações de origem e destino\n",
    "                arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "                # realiza a extração do arquivo zip\n",
    "                zip_ref.extractall(path = f\"{salvar_onde}\", members=arquivos_para_extrair)\n",
    "                \n",
    "                # renomeia o arquivo extraído com o novo nome\n",
    "                os.replace(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "                \n",
    "            os.remove(path)\n",
    "        # leitura do arquivo CSV em um dataframe Spark\n",
    "        # Obtém a lista de arquivos no diretório\n",
    "        lista_arquivos_no_diretorio = [os.path.join(salvar_onde, nome) for nome in os.listdir(salvar_onde) if nome.endswith(\".csv\")]\n",
    "        # Lê o arquivo CSV em um dataframe Spark e adiciona uma coluna com o nome do arquivo\n",
    "        if len(lista_arquivos_no_diretorio) == 1:\n",
    "            dados = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"false\")\\\n",
    "                .option(\"delimiter\", \";\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load(lista_arquivos_no_diretorio[0])\n",
    "            dados.withColumn(\"NOME_ARQUIVO\", lit(lista_arquivos_no_diretorio[0]))\n",
    "        # Lê cada arquivo CSV em um dataframe Spark e adiciona uma coluna com o nome do arquivo\n",
    "        else:\n",
    "            dados = None\n",
    "            for arquivo_no_diretorio in lista_arquivos_no_diretorio:\n",
    "                if dados is None:\n",
    "                    dados = spark.read.format(\"csv\")\\\n",
    "                        .option(\"header\", \"false\")\\\n",
    "                        .option(\"delimiter\", \";\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .load(arquivo_no_diretorio)\n",
    "                    dados = dados.withColumn(\"NOME_ARQUIVO\", lit(arquivo_no_diretorio.split('\\\\')[-1]))\n",
    "                else:\n",
    "                    #print(arquivo_no_diretorio)\n",
    "                    dados_incrementados = spark.read.format(\"csv\")\\\n",
    "                        .option(\"header\", \"false\")\\\n",
    "                        .option(\"delimiter\", \";\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .load(arquivo_no_diretorio)\n",
    "                    dados_incrementados = dados_incrementados.withColumn(\"NOME_ARQUIVO\", lit(arquivo_no_diretorio.split('\\\\')[-1]))\n",
    "                    dados = dados.union(dados_incrementados)\n",
    "        # USA O MÉTODO WITHCOLUMNRENAMED() PARA RENOMEAR AS COLUNAS\n",
    "        for NOME_ANTIGO, NOVO_NOME in self.CNPJ_ESQUEMA[''.join(filter(str.isalpha,nome_arquivo_download.split('.')[0]))].items():\n",
    "            dados = dados.withColumnRenamed(NOME_ANTIGO, NOVO_NOME)\n",
    "        dados.show(1, vertical=True)\n",
    "        return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/'\n",
    "EC_SOCIOS = EXTRATOR_CNPJ(url=url, nome_arquivo='Socios', extensao='zip')\n",
    "SOCIOS = EC_SOCIOS.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------\n",
      " CNPJ_BASE                         | 192669               \n",
      " TIPO_SOCIO                        | 2                    \n",
      " NOME_SOCIO                        | RENI SILVA DIAS A... \n",
      " CPF_CNPJ                          | ***838288**          \n",
      " CODIGO_QUALIFICACAO_SOCIO         | 22                   \n",
      " DATA_ENTRADA_SOCIEDADE            | 20091211             \n",
      " PERCENTUAL_CAPITAL_SOCIAL         | null                 \n",
      " CPF_REPRESENTANTE                 | ***000000**          \n",
      " NOME_REPRESENTANTE                | null                 \n",
      " CODIGO_QUALIFICACAO_REPRESENTANTE | 0                    \n",
      " FAIXA_ETARIA                      | 8                    \n",
      " NOME_ARQUIVO                      | CNPJ_SOCIOS0.csv     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name, lit\n",
    "import os\n",
    "# Define ou busca uma sessão do Spark\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[2]\")\\\n",
    "        .appName(\"OnlineReader\")\\\n",
    "        .getOrCreate()\n",
    "SOCIOS ={\n",
    "    \"_c0\" : \"CNPJ_BASE\",\n",
    "    \"_c1\" : \"TIPO_SOCIO\",\n",
    "    \"_c2\" : \"NOME_SOCIO\",\n",
    "    \"_c3\" : \"CPF_CNPJ\",\n",
    "    \"_c4\" : \"CODIGO_QUALIFICACAO_SOCIO\",\n",
    "    \"_c5\" : \"DATA_ENTRADA_SOCIEDADE\",\n",
    "    \"_c6\" : \"PERCENTUAL_CAPITAL_SOCIAL\",\n",
    "    \"_c7\" : \"CPF_REPRESENTANTE\",\n",
    "    \"_c8\" : \"NOME_REPRESENTANTE\",\n",
    "    \"_c9\" : \"CODIGO_QUALIFICACAO_REPRESENTANTE\",\n",
    "    \"_c10\" : \"FAIXA_ETARIA\"\n",
    "}\n",
    "salvar_onde = r\".\\RAW\\SOCIOS\"\n",
    "lista_arquivos_no_diretorio = [os.path.join(salvar_onde, nome) for nome in os.listdir(salvar_onde) if nome.endswith(\".csv\")]\n",
    "        # Lê o arquivo CSV em um dataframe Spark e adiciona uma coluna com o nome do arquivo\n",
    "if len(lista_arquivos_no_diretorio) == 1:\n",
    "    dados = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "        .option(\"delimiter\", \";\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load(lista_arquivos_no_diretorio[0])\n",
    "    dados.withColumn(\"NOME_ARQUIVO\", lit(lista_arquivos_no_diretorio[0]))\n",
    "# Lê cada arquivo CSV em um dataframe Spark e adiciona uma coluna com o nome do arquivo\n",
    "else:\n",
    "    dados = None\n",
    "    for arquivo_no_diretorio in lista_arquivos_no_diretorio:\n",
    "        if dados is None:\n",
    "            dados = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"false\")\\\n",
    "                .option(\"delimiter\", \";\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load(arquivo_no_diretorio)\n",
    "            dados = dados.withColumn(\"NOME_ARQUIVO\", lit(arquivo_no_diretorio.split('\\\\')[-1]))\n",
    "        else:\n",
    "            #print(arquivo_no_diretorio)\n",
    "            dados_incrementados = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"false\")\\\n",
    "                .option(\"delimiter\", \";\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load(arquivo_no_diretorio)\n",
    "            dados_incrementados = dados_incrementados.withColumn(\"NOME_ARQUIVO\", lit(arquivo_no_diretorio.split('\\\\')[-1]))\n",
    "            dados = dados.union(dados_incrementados)\n",
    "# USA O MÉTODO WITHCOLUMNRENAMED() PARA RENOMEAR AS COLUNAS\n",
    "for NOME_ANTIGO, NOVO_NOME in SOCIOS.items():\n",
    "    dados = dados.withColumnRenamed(NOME_ANTIGO, NOVO_NOME)\n",
    "dados.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este dataframe do Simples tem 22651150 Observações\n"
     ]
    }
   ],
   "source": [
    "print(f\"Este dataframe do Simples tem {dados.count()} Observações\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------+\n",
      "|CODIGO_QUALIFICACAO_SOCIO|QUANTIDADE|\n",
      "+-------------------------+----------+\n",
      "|                       31|      3310|\n",
      "|                       65|    302086|\n",
      "|                       53|     18355|\n",
      "|                       28|     70094|\n",
      "|                       26|      1004|\n",
      "|                       22|   5085550|\n",
      "|                       47|         1|\n",
      "|                       52|     84527|\n",
      "|                       16|   1392558|\n",
      "|                       20|        56|\n",
      "|                       54|      2954|\n",
      "|                        5|    531564|\n",
      "|                       17|         6|\n",
      "|                       72|        20|\n",
      "|                       59|    398241|\n",
      "|                        8|     14089|\n",
      "|                       23|       368|\n",
      "|                       49|  13684133|\n",
      "|                       63|       566|\n",
      "|                       10|    367721|\n",
      "+-------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria uma view com o mesmo nome do DataFrame\n",
    "dados.createOrReplaceTempView(\"dados\")\n",
    "\n",
    "# Consulta a view em SQL\n",
    "spark.sql(\"\"\"SELECT CODIGO_QUALIFICACAO_SOCIO, COUNT(*) AS QUANTIDADE \n",
    "            FROM dados \n",
    "            WHERE TIPO_SOCIO = 2\n",
    "            GROUP BY CODIGO_QUALIFICACAO_SOCIO \"\"\").show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva no disco e lê após isso\n",
    "``` PYTHON\n",
    "# Libs\n",
    "import requests # SE FOR USAR REQUESTS\n",
    "import urllib.request # SE FOR USAR URLLIB\n",
    "from pySmartDL import SmartDL # SE FOR USAR PYSMARTDL\n",
    "import zipfile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define ou busca uma sessão do Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "    .appName(\"OnlineReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define a url de download dos dados\n",
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/Simples.zip'\n",
    "# Pega o nome do arquivo pela url\n",
    "arquivo = url.split('/')[-1]\n",
    "# Define o caminho absoluto do diretório.\n",
    "salvar_onde = f\"{current_dir}/RAW/{arquivo.split('.')[0]}/\"\n",
    "\n",
    "# cria a pasta para armazenar o arquivo, se ela não existir\n",
    "if not os.path.exists(salvar_onde):\n",
    "    os.makedirs(salvar_onde)\n",
    "\n",
    "### Com requests\n",
    "\"\"\"\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "\"\"\"\n",
    "### Com urllib\n",
    "\n",
    "# faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "\n",
    "### Com SmartDL\n",
    "\"\"\"\n",
    "    dest = os.path.join(salvar_onde, arquivo)\n",
    "    obj = SmartDL(url, dest, threads=4)\n",
    "    obj.start()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Imprime o caminho do diretório de download\n",
    "print(salvar_onde)\n",
    "\"\"\"\n",
    "\n",
    "# Descompactação do arquivo\n",
    "with zipfile.ZipFile(os.path.join(salvar_onde, arquivo), 'r') as zip_ref:\n",
    "\n",
    "    # obtem o nome do primeiro arquivo dentro do zip\n",
    "    nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "    # define um novo nome para o arquivo\n",
    "    novo_nome_arquivo = f\"CNPJ_{arquivo.split('.')[0]}.csv\"\n",
    "\n",
    "    # cria um dicionário com as informações de origem e destino\n",
    "    arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "    # realiza a extração do arquivo zip\n",
    "    zip_ref.extractall(path = f\"{salvar_onde}/\", members=arquivos_para_extrair)\n",
    "    \n",
    "    # renomeia o arquivo extraído com o novo nome\n",
    "    os.rename(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "\n",
    "\"\"\"\n",
    "# imprime o nome do arquivo dentro do zip e o novo nome\n",
    "print(f\"Arquivo dentro do zip: {nome_original_arquivo_zip}\")\n",
    "print(f\"Novo nome do arquivo: {novo_nome_arquivo}\")\n",
    "\"\"\"\n",
    "\n",
    "# Define o caminho absoluto para o arquivo\n",
    "csv_file = os.path.join(salvar_onde, novo_nome_arquivo)\n",
    "\n",
    "# Lê o arquivo em um dataframe Spark\n",
    "dados = spark.read.options(delimiter=\";\", header=False, inferSchema=True).csv(csv_file)\n",
    "\n",
    "# Plota primeira linha do dataframe\n",
    "dados.show(1, vertical=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import requests # SE FOR USAR REQUESTS\n",
    "import urllib.request # SE FOR USAR URLLIB\n",
    "from pySmartDL import SmartDL # SE FOR USAR PYSMARTDL\n",
    "import zipfile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define ou busca uma sessão do Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "    .appName(\"OnlineReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define a url de download dos dados\n",
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/Simples.zip'\n",
    "# Pega o nome do arquivo pela url\n",
    "arquivo = url.split('/')[-1]\n",
    "# Define o caminho absoluto do diretório.\n",
    "salvar_onde = f\"{current_dir}/RAW/{arquivo.split('.')[0]}/\"\n",
    "\n",
    "# cria a pasta para armazenar o arquivo, se ela não existir\n",
    "if not os.path.exists(salvar_onde):\n",
    "    os.makedirs(salvar_onde)\n",
    "\n",
    "### Com requests\n",
    "\"\"\"\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "\"\"\"\n",
    "### Com urllib\n",
    "\n",
    "# faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "\n",
    "### Com SmartDL\n",
    "\"\"\"\n",
    "    dest = os.path.join(salvar_onde, arquivo)\n",
    "    obj = SmartDL(url, dest, threads=4)\n",
    "    obj.start()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Imprime o caminho do diretório de download\n",
    "print(salvar_onde)\n",
    "\"\"\"\n",
    "\n",
    "# Descompactação do arquivo\n",
    "with zipfile.ZipFile(os.path.join(salvar_onde, arquivo), 'r') as zip_ref:\n",
    "\n",
    "    # obtem o nome do primeiro arquivo dentro do zip\n",
    "    nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "    # define um novo nome para o arquivo\n",
    "    novo_nome_arquivo = f\"CNPJ_{arquivo.split('.')[0]}.csv\"\n",
    "\n",
    "    # cria um dicionário com as informações de origem e destino\n",
    "    arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "    # realiza a extração do arquivo zip\n",
    "    zip_ref.extractall(path = f\"{salvar_onde}/\", members=arquivos_para_extrair)\n",
    "    \n",
    "    # renomeia o arquivo extraído com o novo nome\n",
    "    os.rename(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "\n",
    "\"\"\"\n",
    "# imprime o nome do arquivo dentro do zip e o novo nome\n",
    "print(f\"Arquivo dentro do zip: {nome_original_arquivo_zip}\")\n",
    "print(f\"Novo nome do arquivo: {novo_nome_arquivo}\")\n",
    "\"\"\"\n",
    "\n",
    "# Define o caminho absoluto para o arquivo\n",
    "csv_file = os.path.join(salvar_onde, novo_nome_arquivo)\n",
    "\n",
    "# Lê o arquivo em um dataframe Spark\n",
    "dados = spark.read.options(delimiter=\";\", header=False, inferSchema=True).csv(csv_file)\n",
    "\n",
    "# Plota primeira linha do dataframe\n",
    "dados.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
