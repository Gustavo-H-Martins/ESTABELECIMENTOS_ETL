{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from unidecode import unidecode \n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.option_context(10,5)\n",
    "\n",
    "#define o caminho do diretório atual\n",
    "current_dir = os.getcwd()\n",
    "file_logs = current_dir.replace(r'ticket\\dados',r'logs\\ticket.log')\n",
    "# configurando o registro de logs\n",
    "logging.basicConfig(level=logging.DEBUG, filename=file_logs,encoding='utf-8', format=\"%(asctime)s - %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gusta\\\\OneDrive\\\\Documentos\\\\GitHub\\\\coletor_leads_vouchers\\\\ticket\\\\dados\\\\BASE_TICKET.lz4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pega o arquivo gerado\n",
    "base_ticket = current_dir + r'\\BASE_TICKET.lz4'\n",
    "base_ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual cabeçalho nós usamos mesmo?\n",
    "cabecalho = [\"CNPJ\", \"RAZAO_SOCIAL\", \n",
    "            \"ESTABELECIMENTO\", \"ENDERECO\", \n",
    "            \"BAIRRO\", \"CIDADE\", \n",
    "            \"UF\", \"CEP\", \"TELEFONE\",\n",
    "            \"LATITUDE\", \"LONGITUDE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregada os dados no dataframe pandas aqui, simples né?\n",
    "\n",
    "dados  = pd.read_parquet(path=base_ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "LZ4F_decompress failed with code: ERROR_frameType_unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m chunk_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m# ajuste o tamanho do pedaço conforme necessário\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m lz4\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mopen(base_ticket, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> 5\u001b[0m     chunk \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mread(size\u001b[39m=\u001b[39;49mchunk_size)\n\u001b[0;32m      6\u001b[0m     df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mfrom_pandas(chunk) \u001b[39m# converte o pedaço em um dataframe polars\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\GitHub\\coletor_leads_vouchers\\.venv\\lib\\site-packages\\lz4\\frame\\__init__.py:668\u001b[0m, in \u001b[0;36mLZ4FrameFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[0;32m    667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreadall()\n\u001b[1;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\_compression.py:103\u001b[0m, in \u001b[0;36mDecompressReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         rawblock \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 103\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(rawblock, size)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    105\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\GitHub\\coletor_leads_vouchers\\.venv\\lib\\site-packages\\lz4\\frame\\__init__.py:414\u001b[0m, in \u001b[0;36mLZ4FrameDecompressor.decompress\u001b[1;34m(self, data, max_length)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unconsumed_data:\n\u001b[0;32m    412\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unconsumed_data \u001b[39m+\u001b[39m data\n\u001b[1;32m--> 414\u001b[0m decompressed, bytes_read, eoframe \u001b[39m=\u001b[39m decompress_chunk(\n\u001b[0;32m    415\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context,\n\u001b[0;32m    416\u001b[0m     data,\n\u001b[0;32m    417\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m    418\u001b[0m     return_bytearray\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_bytearray,\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m bytes_read \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    422\u001b[0m     \u001b[39mif\u001b[39;00m eoframe:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: LZ4F_decompress failed with code: ERROR_frameType_unknown"
     ]
    }
   ],
   "source": [
    "import lz4.frame\n",
    "import polars as pl\n",
    "chunk_size = 128 * 1024 * 1024 # ajuste o tamanho do pedaço conforme necessário\n",
    "with lz4.frame.open(base_ticket, 'r') as file:\n",
    "    chunk = file.read(size=chunk_size)\n",
    "    df = pl.from_pandas(chunk) # converte o pedaço em um dataframe polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a parte de transform de fato está toda aqui, bem simples:\n",
    "# com quaanto de dadps começou?\n",
    "logging.info(f'Tinham: {dados.shape[0]} dados')\n",
    "# Remove os dados duplicados, estranho que sempre aparecem\n",
    "dados.drop_duplicates(inplace=True, ignore_index=True)\n",
    "dados['LISTA_NEGRA'] = dados['LISTA_NEGRA'].astype('boolean')\n",
    "# coloca tudo em uppercase\n",
    "dados['ESTABELECIMENTOS'] = dados['ESTABELECIMENTOS'].str.upper()\n",
    "dados['LOGRADOURO'] = dados['LOGRADOURO'].str.upper()\n",
    "dados['BAIRRO'] = dados['BAIRRO'].str.upper()\n",
    "dados['MUNICIPIO'] = dados['MUNICIPIO'].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "# concatena \n",
    "dados['ENDERECO'] = dados['TIPO_LOGRADOURO'].map(str) + ' ' + dados['LOGRADOURO'].map(str) + ', ' + dados['NUMERO'].map(str) + ', ' + dados['COMPLEMENTO'].map(str) + ', ' + dados['BAIRRO'].map(str)  + ', ' + dados['MUNICIPIO'].map(str) + '-' + dados['UF'].map(str)\n",
    "\n",
    "\"\"\"\n",
    "# tá ai uma coluna inútil, mas com muita utilidade\n",
    "dados['Cidade_UF'] = dados['MUNICIPIO'].map(str) + ', ' + dados['UF'].map(str)\n",
    "\"\"\"\n",
    "# Limpando a lista negra\n",
    "logging.info(f'neste momento estamos limpando os da lista_negra')\n",
    "lista_negra = dados[dados['LISTA_NEGRA'] == True]\n",
    "dados.drop(dados[dados['LISTA_NEGRA'] == True ].index, inplace=True)\n",
    "# conta quando de dados sobrou\n",
    "logging.info(f'temos: {dados.shape[0]} estabelecimentos fora da lista negra')\n",
    "logging.info(f'e também temos: {lista_negra.shape[0]} estabelecimentos na lista negra')\n",
    "\n",
    "# filtrando as colunas que vamos usar depois de toda a brincadeira\n",
    "dados = dados[['ESTABELECIMENTOS',\t'ENDERECO',\t'BAIRRO',\t'MUNICIPIO',\t'UF',\t'CEP',\t'TELEFONE', 'EMAIL', 'LATITUDE',\t'LONGITUDE', 'BANDEIRA', 'SITE']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicionando a coluna padrão ibge, é muito útil para colocar em mapas e essas coisas legais de geoprocessamento\n",
    "CIDADE_PADRAO_IBGE=[]\n",
    "for municipio in dados['MUNICIPIO']:\n",
    "    CIDADE_PADRAO_IBGE.append(unidecode(str(municipio)))\n",
    "dados['CIDADE_PADRAO_IBGE'] = CIDADE_PADRAO_IBGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tirando os telefones fakes ou sem valor interessante\n",
    "telefone = []\n",
    "for i in dados['TELEFONE']:\n",
    "    if len(str(i)) < 9:\n",
    "        telefone.append('Indisponível')\n",
    "    else:\n",
    "        telefone.append(str(i))\n",
    "dados['TELEFONE'] = telefone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conta quantos de dados tinham antes de tirar os telefones nulos\n",
    "logging.info(f'ficaram: {dados.shape[0]} dados')\n",
    "dados.drop(dados[dados['TELEFONE'] == 'Indisponível'].index, inplace=True)\n",
    "# contando quantos ficaram depois de tirar os nulos\n",
    "logging.info(f'ficaram: {dados.shape[0]} dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva tudo novamente desta vez com um csv e outro excel, a galera gosta de \"variedades\"\n",
    "dados.to_csv(base_benvisodexo,sep=';', index=False, encoding='utf-8')\n",
    "dados.to_excel('./BASE_SODEXO.xlsx',sheet_name='BASE SODEXO', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
